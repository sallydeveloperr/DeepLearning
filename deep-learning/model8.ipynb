{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcd775ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RestNet(Skip connection, Regidual Block)  잔차를 레이어에 더해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "015d20df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 64, 32, 32]), torch.Size([2, 3, 32, 32]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv - batchn - Relu - conv -batchn \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "conv1 = nn.Conv2d(3,32,kernel_size=3,padding=1)\n",
    "batch1 = nn.BatchNorm2d(32)\n",
    "relu = nn.ReLU()\n",
    "conv2 = nn.Conv2d(32,64,kernel_size=3,padding=1)\n",
    "batch2 = nn.BatchNorm2d(64)\n",
    "\n",
    "x = torch.randn(2,3,32,32)\n",
    "x_ = x  # 스킵커넥션을 위해서 초기 입력을 저장\n",
    "\n",
    "x = conv1(x)\n",
    "x = batch1(x)\n",
    "x = relu(x)\n",
    "x = conv2(x)\n",
    "x = batch2(x)\n",
    "x.size() , x_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d6cb13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 32, 32])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample = nn.Conv2d(3,64,kernel_size=1)\n",
    "down_x = downsample(x_)\n",
    "down_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ee954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channel,out_channel,hidden_dim):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel,hidden_dim,kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim,out_channel,kernel_size=3,padding=1)\n",
    "        self.batch1 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.batch2 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.downsample = nn.Conv2d(in_channel,out_channel,kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        x_ = x\n",
    "        x_ = self.downsample(x_)\n",
    "\n",
    "        x = self.relu(self.batch1(self.conv1(x)))\n",
    "        x = self.batch2(self.conv2(x))        \n",
    "        x += x_\n",
    "        out = self.relu(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a9f3530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 32, 32])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.randn(1,256,32,32)\n",
    "t = BasicBlock(256,256,256)\n",
    "t(sample).size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35789f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, class_num = 10):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.b1 = BasicBlock(3,64,32) \n",
    "        self.b2 = BasicBlock(64,256,128)\n",
    "        self.b3 = BasicBlock(256,256,256)\n",
    "\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*4*4 , 2048) \n",
    "        self.fc2 = nn.Linear(2048 , 512)\n",
    "        self.fc3 = nn.Linear(512 , class_num)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "    def forward(self,x):\n",
    "        x = self.dropout1(self.pool(self.b1(x)))\n",
    "        x = self.dropout1(self.pool(self.b2(x)))  \n",
    "        x = self.dropout2(self.pool(self.b3(x))) \n",
    "        x = torch.flatten(x, start_dim=1)             \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        out = self.fc3(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6c2113d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.randn(1,3,32,32)\n",
    "model = ResNet(2)\n",
    "test = model(sample)\n",
    "test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d8509c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch : 1/20: 100%|██████████| 206/206 [00:24<00:00,  8.32it/s, loss=2.9]   \n",
      "epoch : 2/20: 100%|██████████| 206/206 [00:26<00:00,  7.71it/s, loss=0.158]   \n",
      "epoch : 3/20: 100%|██████████| 206/206 [00:24<00:00,  8.29it/s, loss=0.0269]  \n",
      "epoch : 4/20: 100%|██████████| 206/206 [00:26<00:00,  7.83it/s, loss=0.00969] \n",
      "epoch : 5/20: 100%|██████████| 206/206 [00:26<00:00,  7.68it/s, loss=1.4]     \n",
      "epoch : 6/20: 100%|██████████| 206/206 [00:27<00:00,  7.39it/s, loss=0.00175] \n",
      "epoch : 7/20: 100%|██████████| 206/206 [00:27<00:00,  7.60it/s, loss=0.0051]  \n",
      "epoch : 8/20: 100%|██████████| 206/206 [00:26<00:00,  7.77it/s, loss=9.83e-6] \n",
      "epoch : 9/20: 100%|██████████| 206/206 [00:26<00:00,  7.73it/s, loss=8.2e-5]  \n",
      "epoch : 10/20: 100%|██████████| 206/206 [00:27<00:00,  7.59it/s, loss=0.0065]  \n",
      "epoch : 11/20: 100%|██████████| 206/206 [00:26<00:00,  7.85it/s, loss=0.0152]  \n",
      "epoch : 12/20: 100%|██████████| 206/206 [00:27<00:00,  7.50it/s, loss=0.00307] \n",
      "epoch : 13/20: 100%|██████████| 206/206 [00:26<00:00,  7.70it/s, loss=0.00286] \n",
      "epoch : 14/20: 100%|██████████| 206/206 [00:26<00:00,  7.77it/s, loss=0]       \n",
      "epoch : 15/20: 100%|██████████| 206/206 [00:27<00:00,  7.48it/s, loss=1.19e-7] \n",
      "epoch : 16/20: 100%|██████████| 206/206 [00:28<00:00,  7.31it/s, loss=0]       \n",
      "epoch : 17/20: 100%|██████████| 206/206 [00:28<00:00,  7.24it/s, loss=0]       \n",
      "epoch : 18/20: 100%|██████████| 206/206 [00:28<00:00,  7.18it/s, loss=9.98e-5] \n",
      "epoch : 19/20: 100%|██████████| 206/206 [00:26<00:00,  7.71it/s, loss=2.98e-7] \n",
      "epoch : 20/20: 100%|██████████| 206/206 [00:29<00:00,  7.10it/s, loss=0.000207]\n"
     ]
    }
   ],
   "source": [
    "# 데이터는 인간 - 말\n",
    "# 학습 - 평가\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "train_dataset =  datasets.ImageFolder(root = './data/train', transform=transform)\n",
    "test_dataset =  datasets.ImageFolder(root = './data/test', transform=transform)\n",
    "train_loader = DataLoader(train_dataset,batch_size=5,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=5,shuffle=False)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = ResNet(2)\n",
    "model.to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "epochs = 20\n",
    "# 학습루프\n",
    "for epoch in range(epochs):\n",
    "    tqdm_obj = tqdm(train_loader,desc=f'epoch : {epoch+1}/{epochs}')\n",
    "    for data, label in tqdm_obj:\n",
    "        optim.zero_grad()\n",
    "        preds = model(data.to(device))\n",
    "        loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        tqdm_obj.set_postfix(loss=loss.item())\n",
    "        \n",
    "\n",
    "torch.save(model.state_dict(), 'resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87950089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 52/52 [00:07<00:00,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2955, Test Accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "model.load_state_dict(torch.load('resnet.pth',map_location=device,weights_only=True))\n",
    "# 예측\n",
    "# 평가 루프\n",
    "# test_loader가 이미 정의되어 있다고 가정\n",
    "model.eval()  # 평가 모드로 전환 (dropout, batchnorm 등 비활성화)\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "    for data, label in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        preds = model(data)\n",
    "        loss = criterion(preds, label)\n",
    "        total_loss += loss.item() * data.size(0)  # 배치 손실 합산\n",
    "        total_correct += (preds.argmax(dim=1) == label).sum().item()\n",
    "        total_samples += data.size(0)\n",
    "\n",
    "avg_loss = total_loss / total_samples\n",
    "accuracy = total_correct / total_samples\n",
    "\n",
    "print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c1c76e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 206/206 [00:09<00:00, 21.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0030, Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # 평가 모드로 전환 (dropout, batchnorm 등 비활성화)\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "    for data, label in tqdm(train_loader, desc=\"Evaluating\"):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        preds = model(data)\n",
    "        loss = criterion(preds, label)\n",
    "        total_loss += loss.item() * data.size(0)  # 배치 손실 합산\n",
    "        total_correct += (preds.argmax(dim=1) == label).sum().item()\n",
    "        total_samples += data.size(0)\n",
    "\n",
    "avg_loss = total_loss / total_samples\n",
    "accuracy = total_correct / total_samples\n",
    "\n",
    "print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40e0da53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.resnet import resnet50\n",
    "resnet50()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
