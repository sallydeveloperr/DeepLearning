{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511f35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀\n",
    "# 출력의 개수를 1개로\n",
    "# 손실함수를 MSE나 기타 등등..\n",
    "# 데이터셋 과 데이터 로드를 커스텀하게 정의해서 사용\n",
    "# 나머지는 동일한 패턴으로 ... 학습 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d93f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608efacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\sally\\AppData\\Local\\Temp\\ipykernel_40796\\2445309702.py:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 데이터 프레임\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "class BostonDataSet(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1,1)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f55c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = BostonDataSet(data, target)  # 데이터를 X, y 를 한쌍으로 묶어\n",
    "X_train_loader = DataLoader(X_dataset ,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93f4ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 모델 정의\n",
    "import torch.nn as nn\n",
    "class BostonRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BostonRegression,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f86435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "model = BostonRegression(data.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optim = Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e277caaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch : 1/100: 100%|██████████| 16/16 [00:00<00:00, 124.25it/s, loss=108.9569]\n",
      "epoch : 2/100: 100%|██████████| 16/16 [00:00<00:00, 161.85it/s, loss=56.1915]\n",
      "epoch : 3/100: 100%|██████████| 16/16 [00:00<00:00, 169.95it/s, loss=29.4519]\n",
      "epoch : 4/100: 100%|██████████| 16/16 [00:00<00:00, 168.37it/s, loss=58.2753]\n",
      "epoch : 5/100: 100%|██████████| 16/16 [00:00<00:00, 128.39it/s, loss=43.8207] \n",
      "epoch : 6/100: 100%|██████████| 16/16 [00:00<00:00, 138.91it/s, loss=75.5782]\n",
      "epoch : 7/100: 100%|██████████| 16/16 [00:00<00:00, 135.40it/s, loss=46.4046]\n",
      "epoch : 8/100: 100%|██████████| 16/16 [00:00<00:00, 137.10it/s, loss=61.9120]\n",
      "epoch : 9/100: 100%|██████████| 16/16 [00:00<00:00, 89.62it/s, loss=52.3022]\n",
      "epoch : 10/100: 100%|██████████| 16/16 [00:00<00:00, 80.09it/s, loss=36.8391]\n",
      "epoch : 11/100: 100%|██████████| 16/16 [00:00<00:00, 103.50it/s, loss=77.6346]\n",
      "epoch : 12/100: 100%|██████████| 16/16 [00:00<00:00, 148.93it/s, loss=22.3039]\n",
      "epoch : 13/100: 100%|██████████| 16/16 [00:00<00:00, 149.66it/s, loss=51.7607]\n",
      "epoch : 14/100: 100%|██████████| 16/16 [00:00<00:00, 119.24it/s, loss=43.2357]\n",
      "epoch : 15/100: 100%|██████████| 16/16 [00:00<00:00, 135.14it/s, loss=31.3796]\n",
      "epoch : 16/100: 100%|██████████| 16/16 [00:00<00:00, 196.86it/s, loss=87.0558]\n",
      "epoch : 17/100: 100%|██████████| 16/16 [00:00<00:00, 170.88it/s, loss=81.5115]\n",
      "epoch : 18/100: 100%|██████████| 16/16 [00:00<00:00, 187.60it/s, loss=13.1240]\n",
      "epoch : 19/100: 100%|██████████| 16/16 [00:00<00:00, 186.12it/s, loss=65.0876]\n",
      "epoch : 20/100: 100%|██████████| 16/16 [00:00<00:00, 188.07it/s, loss=53.1553]\n",
      "epoch : 21/100: 100%|██████████| 16/16 [00:00<00:00, 206.36it/s, loss=48.3983]\n",
      "epoch : 22/100: 100%|██████████| 16/16 [00:00<00:00, 182.12it/s, loss=67.2843]\n",
      "epoch : 23/100: 100%|██████████| 16/16 [00:00<00:00, 183.62it/s, loss=96.3175]\n",
      "epoch : 24/100: 100%|██████████| 16/16 [00:00<00:00, 149.36it/s, loss=16.1069]\n",
      "epoch : 25/100: 100%|██████████| 16/16 [00:00<00:00, 149.12it/s, loss=45.2017]\n",
      "epoch : 26/100: 100%|██████████| 16/16 [00:00<00:00, 138.64it/s, loss=36.0082]\n",
      "epoch : 27/100: 100%|██████████| 16/16 [00:00<00:00, 174.23it/s, loss=44.9962]\n",
      "epoch : 28/100: 100%|██████████| 16/16 [00:00<00:00, 255.15it/s, loss=37.4461]\n",
      "epoch : 29/100: 100%|██████████| 16/16 [00:00<00:00, 278.17it/s, loss=19.7476]\n",
      "epoch : 30/100: 100%|██████████| 16/16 [00:00<00:00, 236.62it/s, loss=22.8002]\n",
      "epoch : 31/100: 100%|██████████| 16/16 [00:00<00:00, 188.74it/s, loss=42.4337]\n",
      "epoch : 32/100: 100%|██████████| 16/16 [00:00<00:00, 284.73it/s, loss=28.1171]\n",
      "epoch : 33/100: 100%|██████████| 16/16 [00:00<00:00, 322.92it/s, loss=48.6712]\n",
      "epoch : 34/100: 100%|██████████| 16/16 [00:00<00:00, 277.85it/s, loss=44.1473]\n",
      "epoch : 35/100: 100%|██████████| 16/16 [00:00<00:00, 281.14it/s, loss=29.7453]\n",
      "epoch : 36/100: 100%|██████████| 16/16 [00:00<00:00, 370.69it/s, loss=41.3883]\n",
      "epoch : 37/100: 100%|██████████| 16/16 [00:00<00:00, 303.77it/s, loss=19.5865]\n",
      "epoch : 38/100: 100%|██████████| 16/16 [00:00<00:00, 340.57it/s, loss=43.3420]\n",
      "epoch : 39/100: 100%|██████████| 16/16 [00:00<00:00, 428.13it/s, loss=53.5464]\n",
      "epoch : 40/100: 100%|██████████| 16/16 [00:00<00:00, 326.02it/s, loss=13.3503]\n",
      "epoch : 41/100: 100%|██████████| 16/16 [00:00<00:00, 308.27it/s, loss=29.1545]\n",
      "epoch : 42/100: 100%|██████████| 16/16 [00:00<00:00, 355.41it/s, loss=53.9469]\n",
      "epoch : 43/100: 100%|██████████| 16/16 [00:00<00:00, 317.75it/s, loss=23.6310]\n",
      "epoch : 44/100: 100%|██████████| 16/16 [00:00<00:00, 271.07it/s, loss=13.8067]\n",
      "epoch : 45/100: 100%|██████████| 16/16 [00:00<00:00, 352.39it/s, loss=47.6071]\n",
      "epoch : 46/100: 100%|██████████| 16/16 [00:00<00:00, 381.12it/s, loss=45.5617]\n",
      "epoch : 47/100: 100%|██████████| 16/16 [00:00<00:00, 349.94it/s, loss=29.4244]\n",
      "epoch : 48/100: 100%|██████████| 16/16 [00:00<00:00, 396.51it/s, loss=22.8658]\n",
      "epoch : 49/100: 100%|██████████| 16/16 [00:00<00:00, 338.55it/s, loss=48.4519]\n",
      "epoch : 50/100: 100%|██████████| 16/16 [00:00<00:00, 368.84it/s, loss=21.0957]\n",
      "epoch : 51/100: 100%|██████████| 16/16 [00:00<00:00, 326.12it/s, loss=25.3285]\n",
      "epoch : 52/100: 100%|██████████| 16/16 [00:00<00:00, 436.86it/s, loss=33.1448]\n",
      "epoch : 53/100: 100%|██████████| 16/16 [00:00<00:00, 359.81it/s, loss=26.7125]\n",
      "epoch : 54/100: 100%|██████████| 16/16 [00:00<00:00, 375.68it/s, loss=66.4246]\n",
      "epoch : 55/100: 100%|██████████| 16/16 [00:00<00:00, 432.37it/s, loss=56.0203]\n",
      "epoch : 56/100: 100%|██████████| 16/16 [00:00<00:00, 463.52it/s, loss=34.5084]\n",
      "epoch : 57/100: 100%|██████████| 16/16 [00:00<00:00, 441.59it/s, loss=37.9342]\n",
      "epoch : 58/100: 100%|██████████| 16/16 [00:00<00:00, 370.11it/s, loss=41.3463]\n",
      "epoch : 59/100: 100%|██████████| 16/16 [00:00<00:00, 380.30it/s, loss=13.1121]\n",
      "epoch : 60/100: 100%|██████████| 16/16 [00:00<00:00, 393.74it/s, loss=21.4797]\n",
      "epoch : 61/100: 100%|██████████| 16/16 [00:00<00:00, 408.48it/s, loss=59.2104]\n",
      "epoch : 62/100: 100%|██████████| 16/16 [00:00<00:00, 483.28it/s, loss=23.7473]\n",
      "epoch : 63/100: 100%|██████████| 16/16 [00:00<00:00, 378.78it/s, loss=15.7392]\n",
      "epoch : 64/100: 100%|██████████| 16/16 [00:00<00:00, 443.94it/s, loss=33.7139]\n",
      "epoch : 65/100: 100%|██████████| 16/16 [00:00<00:00, 458.47it/s, loss=35.2421]\n",
      "epoch : 66/100: 100%|██████████| 16/16 [00:00<00:00, 427.14it/s, loss=26.9592]\n",
      "epoch : 67/100: 100%|██████████| 16/16 [00:00<00:00, 329.58it/s, loss=18.2518]\n",
      "epoch : 68/100: 100%|██████████| 16/16 [00:00<00:00, 340.64it/s, loss=33.5696]\n",
      "epoch : 69/100: 100%|██████████| 16/16 [00:00<00:00, 475.31it/s, loss=28.7868]\n",
      "epoch : 70/100: 100%|██████████| 16/16 [00:00<00:00, 355.16it/s, loss=30.3995]\n",
      "epoch : 71/100: 100%|██████████| 16/16 [00:00<00:00, 273.61it/s, loss=34.2380]\n",
      "epoch : 72/100: 100%|██████████| 16/16 [00:00<00:00, 255.80it/s, loss=32.7047]\n",
      "epoch : 73/100: 100%|██████████| 16/16 [00:00<00:00, 385.84it/s, loss=40.7223]\n",
      "epoch : 74/100: 100%|██████████| 16/16 [00:00<00:00, 507.55it/s, loss=29.0110]\n",
      "epoch : 75/100: 100%|██████████| 16/16 [00:00<00:00, 442.71it/s, loss=17.7439]\n",
      "epoch : 76/100: 100%|██████████| 16/16 [00:00<00:00, 379.35it/s, loss=20.9329]\n",
      "epoch : 77/100: 100%|██████████| 16/16 [00:00<00:00, 437.48it/s, loss=18.1442]\n",
      "epoch : 78/100: 100%|██████████| 16/16 [00:00<00:00, 455.91it/s, loss=18.1277]\n",
      "epoch : 79/100: 100%|██████████| 16/16 [00:00<00:00, 450.18it/s, loss=40.9738]\n",
      "epoch : 80/100: 100%|██████████| 16/16 [00:00<00:00, 484.05it/s, loss=18.7790]\n",
      "epoch : 81/100: 100%|██████████| 16/16 [00:00<00:00, 474.20it/s, loss=34.1398]\n",
      "epoch : 82/100: 100%|██████████| 16/16 [00:00<00:00, 472.99it/s, loss=54.6131]\n",
      "epoch : 83/100: 100%|██████████| 16/16 [00:00<00:00, 486.90it/s, loss=37.8025]\n",
      "epoch : 84/100: 100%|██████████| 16/16 [00:00<00:00, 464.74it/s, loss=38.1372]\n",
      "epoch : 85/100: 100%|██████████| 16/16 [00:00<00:00, 298.88it/s, loss=17.4939]\n",
      "epoch : 86/100: 100%|██████████| 16/16 [00:00<00:00, 290.12it/s, loss=28.4751]\n",
      "epoch : 87/100: 100%|██████████| 16/16 [00:00<00:00, 306.14it/s, loss=39.7125]\n",
      "epoch : 88/100: 100%|██████████| 16/16 [00:00<00:00, 376.79it/s, loss=18.4754]\n",
      "epoch : 89/100: 100%|██████████| 16/16 [00:00<00:00, 380.05it/s, loss=35.4247]\n",
      "epoch : 90/100: 100%|██████████| 16/16 [00:00<00:00, 382.58it/s, loss=18.1583]\n",
      "epoch : 91/100: 100%|██████████| 16/16 [00:00<00:00, 348.53it/s, loss=30.5965]\n",
      "epoch : 92/100: 100%|██████████| 16/16 [00:00<00:00, 365.74it/s, loss=32.0706]\n",
      "epoch : 93/100: 100%|██████████| 16/16 [00:00<00:00, 438.69it/s, loss=25.1859]\n",
      "epoch : 94/100: 100%|██████████| 16/16 [00:00<00:00, 236.27it/s, loss=36.9795]\n",
      "epoch : 95/100: 100%|██████████| 16/16 [00:00<00:00, 367.08it/s, loss=27.1748]\n",
      "epoch : 96/100: 100%|██████████| 16/16 [00:00<00:00, 403.98it/s, loss=19.5491]\n",
      "epoch : 97/100: 100%|██████████| 16/16 [00:00<00:00, 350.72it/s, loss=27.6458]\n",
      "epoch : 98/100: 100%|██████████| 16/16 [00:00<00:00, 392.32it/s, loss=22.6913]\n",
      "epoch : 99/100: 100%|██████████| 16/16 [00:00<00:00, 446.55it/s, loss=17.6702]\n",
      "epoch : 100/100: 100%|██████████| 16/16 [00:00<00:00, 432.21it/s, loss=19.4236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 100 : avg loss : 24.3647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "epochs = 100\n",
    "# 학습루프\n",
    "for epoch in range(epochs):\n",
    "    tqdm_obj = tqdm(X_train_loader,desc=f'epoch : {epoch+1}/{epochs}')\n",
    "    loss_lists = 0\n",
    "    for data, label in tqdm_obj:\n",
    "        optim.zero_grad()\n",
    "        preds = model(data.to(device))\n",
    "        loss = criterion(preds, label.to(device))\n",
    "        loss_lists += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()    \n",
    "        tqdm_obj.set_postfix({'loss' : f'{loss.item():.4f}'})\n",
    "    avg_loss = loss_lists / len(X_train_loader)\n",
    "print(f'epoch : {epoch+1} : avg loss : {avg_loss:.4f}')\n",
    "        \n",
    "\n",
    "torch.save(model.state_dict(), 'bostonRegression.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98c8b40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 16/16 [00:00<00:00, 1162.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 23.70744079351425 r2 score : 0.7189328633248806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# 평가\n",
    "model.load_state_dict(torch.load('bostonRegression.pth',map_location=device,weights_only=True))\n",
    "# 예측\n",
    "# 평가 루프\n",
    "model.eval()  # 평가 모드로 전환 (dropout, batchnorm 등 비활성화)\n",
    "total_mse = 0\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "r2scores = 0\n",
    "with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "    for data, label in tqdm(X_train_loader, desc=\"Evaluating\"):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        preds = model(data)\n",
    "        r2scores += r2_score(label.cpu().detach().numpy(), preds.cpu().detach().numpy())\n",
    "        mse = criterion(preds, label)        \n",
    "        total_mse += mse.item()\n",
    "print(f\"Test Loss: {total_mse / len(X_train_loader)} r2 score : {r2scores/len(X_train_loader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
