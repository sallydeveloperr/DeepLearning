{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be964f4",
   "metadata": {},
   "source": [
    "#### 다양한 모델을 결합한 앙상블\n",
    "- 앙상블\n",
    "- 다수결 투표 앙상블 (Voting)\n",
    "- 배깅(Bagging)\n",
    "- 에이다부스트(AdaBoost)\n",
    "- 그레이던트 부스팅& XGBoost\n",
    "- 모델 성능 평가 및 비교\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce71897",
   "metadata": {},
   "source": [
    "- 단일모델의 한계\n",
    "    - 과대적합(Overfitting) : 학습데이터에 너무 맞춰져있어서 새로운 데이터에 대한 성능저하 \n",
    "    - 과소적합(Underfitting) : 모델이 너무 단순해서 제대로 학습이 안됨\n",
    "    - 높은 분산(High varience) : 학습 데이터가 조금만 바뀌어도 모델이 크게 달라지는 현상\n",
    "    - 높은 편향(High Bias) : 모델이 진짜 패턴을 포착하지 못함\n",
    "- 앙상블(Ensemble) : 집단지성\n",
    "    - 배깅 : 같은 알고리즘이지만 서로 다른 데이터셋(부트스트랩)  ex.RandomForest, 주요기능: 분산감소\n",
    "    - 부스팅 : 순차적으로 약한 학습기를 강화 ex.AdaBoost, XGBoost, 주요기능: 편향감소\n",
    "    - 스태킹 : 서로 다른 알고리즘을 메타 모델로 학습, 주요기능: 일반화의 성능 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce7540",
   "metadata": {},
   "source": [
    "- 약한 학습기 : 최소한의 모델\n",
    "- 강한 학습기 : 성능이 뛰어난 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684087a",
   "metadata": {},
   "source": [
    "- Voting\n",
    "    - Hard Voting : 다수결 투표\n",
    "        A:고양이\n",
    "        B:강아지\n",
    "        C:고양이\n",
    "    - Soft Voting : 가중치 투표 - 확률을 보고 결정, 보통 Hard Voting 보다 성능이 좋음\n",
    "        고양이, 강아지\n",
    "        A:(0.9,0.1)\n",
    "        B:(0.4,0.6)\n",
    "        C:(0.6,0.2)\n",
    "        평균확률 : ,\n",
    "- Bagging(Bagging - Bootstrap Aggregation)\n",
    "    - Bootstrap : 원본 데이터 1000개면 중복을 허용해서 1000 뽑아 훈련세트 1개를 만듦...\n",
    "    - Aggregation\n",
    "        - 순차적으로 학습을 하고 난 후에 여러개의 모델들을 투표(Voting)해서 최종 결론\n",
    "    - 대표모델은 RandomForest\n",
    "    - 효과 : 과적합을 방지 즉, 모델의 분산을 줄여줌\n",
    "- Boosting\n",
    "    - 모델들이 순서대로 학습, 앞 모델의 실수를 뒷 모델이 보완"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
